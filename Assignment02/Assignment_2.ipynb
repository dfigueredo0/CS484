{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dde1f34-a2a0-4b89-be02-5c371c75a4c8",
   "metadata": {},
   "source": [
    "## Assignment 2 (50 marks)\n",
    "#### =====================================================================================================\n",
    "### Deadline: 09/28 11:59 pm\n",
    "#### ====================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a2bcde-24c5-48bf-add3-d767f0398602",
   "metadata": {},
   "source": [
    "### Problem 1: Perceptron Learning (15 marks)\n",
    "\n",
    "The dataset `lab02_dataset_1.csv` has a *3-dimensional input space* and a class label of *Positive* and *Negative*. For this task, you are **not allowed** to use any *functionalities* of the `sklearn` module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b684c6-d9df-4cce-aa97-5f4c21d8cff5",
   "metadata": {},
   "source": [
    "### 1.a (10 marks)\n",
    "\n",
    "Write a function `my_perceptron()` which applies the perceptron algorithm (refer to the lecture slide covering linear separators for details of this algorithm) on the dataset to create a linear separator. `my_perceptron()` takes the dataset as its input and returns a ***3-dimensional weight vector*** which can be used to create the linear separator (assume `bias = 0`). Use the *initial weights* `w = [3.5,0.5,-2.5]`. Use a classification threshold of `99%` i.e., `my_perceptron()` will terminate once the misclassification rate is less than `1%`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18eb238-4c5e-4703-9b23-3b279c773b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14536582 2.30319913 0.34978878]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def my_perceptron():\n",
    "    data = pd.read_csv('lab02_dataset_1.csv')\n",
    "\n",
    "    inputs = data[['X', 'Y', 'Z']].to_numpy()\n",
    "    classes = data['Class'].map({'Negative': -1, 'Positive': 1}).to_numpy()\n",
    "\n",
    "    weights = np.array([3.5, 0.5, -2.5])\n",
    "    bias = 0\n",
    "    \n",
    "    for iter in range(1000): \n",
    "        err = 0\n",
    "        for i in range(len(inputs)):\n",
    "            a = np.dot(weights, inputs[i]) + bias\n",
    "            predication = 1 if a >= 0 else -1\n",
    "            if predication != classes[i]:\n",
    "                weights += classes[i] * inputs[i]\n",
    "                bias += classes[i]\n",
    "                err += 1\n",
    "        err_rate = err / len(data)\n",
    "        if err_rate <= 0.01:\n",
    "            break\n",
    "    \n",
    "    return weights\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(my_perceptron())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03212d12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48831ddf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922559df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef160c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2624c65c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5881f99a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5067808",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4441e5d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40708839",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74964d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbe412d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6569db0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50940f4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7359106",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2183ee78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c60d175",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33281d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3783ba00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c226a5e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcc5195",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f462e7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d38832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f3232a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008c8678",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c6eede",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0cf1b6f-9b73-43f1-8b0a-bc1db87e1a54",
   "metadata": {},
   "source": [
    "### 1.b (5 marks)\n",
    "\n",
    "Create a *3D plot* which showcases the dataset in a 3D-space alongwith the *linear separator* you obtained from `my_perceptron()`. Use two different colors to represent the data points belonging in the two classes for ease of viewing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22e4a3b-7586-475a-93e9-aacdb01029ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898e703c-af66-416d-89e3-1a3d8390fc89",
   "metadata": {},
   "source": [
    "### Problem 2: SVM Classification (35 marks)\n",
    "\n",
    "`lab02_dataset_2.xlsx` contains the claim history of 27,513 homeowner policies. The following table describes the eleven columns in the dataset.\n",
    "\n",
    "| Name | Description |\n",
    "| --- | --- |\n",
    "| policy | Policy Identifier |\n",
    "| exposure | Duration a Policy exposed in a Year |\n",
    "| num_claims | Number of Claims in a Year |\n",
    "| amt_claims | Total Claim Amount in a Year\t|\n",
    "| f_primary_age_tier | Age Tier of Primary Insured |\n",
    "| f_primary_gender | Gender of Primary Insured |\n",
    "| f_marital | Marital Status of Primary Insured |\n",
    "| f_residence_location | Location of Residence Property |\n",
    "| f_fire_alarm_type | Fire Alarm Type |\n",
    "| f_mile_fire_station | Distance to Nearest Fire Station |\n",
    "| f_aoi_tier | Amount of Insurance Tier |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3f4715-3c4d-4253-9e70-fab96f191ab8",
   "metadata": {},
   "source": [
    "We want to predict the *Frequency* which is the *number of claims per unit of exposure* using the above features.  We first divide the reported number of claims by the exposure. This gives us the *Frequency*.  Next, we put the policies into five groups according to their *Frequency* values. We will use this *Group* as our target variable which has five classes.\n",
    "\n",
    "| Group | Values |\n",
    "| :--- | :--- |\n",
    "| 0 | Frequency = 0 |\n",
    "| 1 | 0 < Frequency <= 1 |\n",
    "| 2 | 1 < Frequency <= 2 |\n",
    "| 3 | 2 < Frequency <= 3 |\n",
    "| 4 | 3 < Frequency |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe26cf5-fd5a-4da0-bb8e-15550898d663",
   "metadata": {},
   "source": [
    "### 2.a (6 marks)\n",
    "Create a new column for the dataset which will indiciate the *Frequency Group* and output the updated dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8349f391-09e8-4202-b36d-a7c23a6419b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e179fc89-649b-44f9-96e2-2007ce9e7302",
   "metadata": {},
   "source": [
    "### 2.b (6 marks)\n",
    "There are seven categorial features in the dataset namely, *f_aoi_tier, f_primary_age_tier, f_fire_alarm_type, f_marital, f_mile_fire_station, f_primary_gender, f_residence_location*. Display all the unique values of these seven categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e93ff8-c65b-472d-89b9-3160fb4ce0cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19fc705d-6a0a-4dd9-afa3-5aa610e9bb82",
   "metadata": {},
   "source": [
    "### 2.c (6 marks)\n",
    "We will train SVM models using those seven categorical features. However, their values are currently all categorical data, but SVM requires them to be numerical. Perform `One-hot Encoding` on these features to obtain an updated dataset which has only numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8822f40-0e48-4755-91c5-1a4809ae593a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a95862c3-225a-477b-a0a5-f3f91105ac46",
   "metadata": {},
   "source": [
    "### 2.d (6 marks)\n",
    "Divide the observations into training and testing partitions. Observations whose *Policy Identifier* starts with the letters A, G, and P will go to the training partition. The remaining observations go to the testing partition. Output the total number of policies present in the Training partition and Testing partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7454f212-5930-49f7-8e10-970db06ecaa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89c10661-ae7c-4a9e-82dc-2a6ac4597e41",
   "metadata": {},
   "source": [
    "### 2.e (6 marks)\n",
    "Train an SVM model using [`LinearSVC`](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html). The input features will be the encoded version of the feature set *f_aoi_tier, f_primary_age_tier, f_fire_alarm_type, f_marital, f_mile_fire_station, f_primary_gender, f_residence_location* and the output is the *Frequency Group*. Use `verbose=1` to observe the optimization steps during the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b90a086-3ea3-48be-882e-e94ea5b5c057",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0e663d4-fd3f-42a7-b544-1aa3403aab42",
   "metadata": {},
   "source": [
    "### 2.f (5 marks)\n",
    "Compute and output the accuracy score on the testing partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97b64ad-ab6b-4bbf-aafd-36a1464464df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
